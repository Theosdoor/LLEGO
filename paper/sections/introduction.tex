\section{Introduction}

% =============================================================================
% PLANNING NOTES
% =============================================================================
% 
% PARAGRAPH 1 - Context & Problem
% - Decision trees are interpretable but hard to optimize
% - Recent work (LLEGO) uses LLMs to guide genetic algorithm evolution
% - LLEGO outperforms baselines on classification tasks
% - BUT: requires expensive API calls during optimization ($0.01-0.10 per call)
% - Cost scales with generations × population size
%
% PARAGRAPH 2 - Our Insight  
% - LLEGO's benefit comes from semantic feature understanding
% - Ablation in LLEGO paper shows "no semantics" hurts performance
% - Key insight: This semantic knowledge is STATIC - doesn't change during evolution
% - Can we extract it ONCE and reuse?
%
% PARAGRAPH 3 - Our Solution
% - Use Sparse Autoencoders (SAEs) to extract feature semantics from LLM internals
% - SAEs decompose LLM activations into interpretable features
% - One forward pass per feature → O(n^2) similarity matrix
% - Use this to guide evolution without any API calls
%
% PARAGRAPH 4 - Key Results
% - Match LLEGO on heart disease (+4%), credit (+0.5%)
% - Outperform GATree baseline on 3/4 datasets
% - Zero API cost during evolution
% - Interpretable: can inspect which SAE features connect related columns
%
% PARAGRAPH 5 - Contributions
% 1. First work combining mechanistic interpretability with decision tree induction
% 2. Novel semantic coherence scoring for tree evolution
% 3. Empirical validation showing SAE priors match LLM-guided performance
% 4. Cost-accuracy analysis showing practical benefits
%
% =============================================================================

% CITED WORKS TO INCLUDE:
% \cite{astorga2025autoformulation} - LLEGO paper
% \cite{liu2024large} - LLMs for optimization  
% \cite{cunningham2023sparse} - SAE fundamentals
% \cite{bricken2023monosemanticity} - Anthropic monosemanticity

LLEGO \cite{astorga2025autoformulation} recently demonstrated that LLM-guided evolution 
can significantly improve decision tree induction. However, this approach requires 
expensive API calls during optimization...

% TODO: Write full introduction