"""
Phase 2: Distillation of Structural and Semantic Priors

Based on Phase 1 findings and LLEGO paper ablations:
- Structural priors from LLMs help with tree quality
- Semantic information CAN help (LLEGO paper §5.3 shows LLEGO_no_semantics underperforms)
- However, repeated LLM calls are expensive - we distill both priors for one-shot use

This module implements:
1. StructuralPrior - Captures LLM's implicit tree structure preferences
2. DistilledEvolution - Evolutionary algorithm using distilled priors (no LLM at runtime)
3. Semantic prior integration - Optional DataFrame of feature similarities (from SAE or embeddings)
"""

import json
import logging
import pickle
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Union
from itertools import combinations
import pandas as pd
import random
import copy

import numpy as np
from scipy import stats

logger = logging.getLogger(__name__)


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class TreeStats:
    """Statistics about a decision tree."""
    depth: int
    size: int  # Total nodes
    n_leaves: int
    n_internal: int
    balance: float  # 0 = unbalanced, 1 = perfectly balanced
    n_features_used: int
    feature_reuse_ratio: float  # features_used / internal_nodes
    
    @classmethod
    def from_tree(cls, tree: dict) -> "TreeStats":
        """Compute statistics from a tree dictionary."""
        depth = compute_depth(tree)
        size = compute_size(tree)
        n_leaves = count_leaves(tree)
        n_internal = size - n_leaves
        balance = compute_balance(tree)
        features = get_features_used(tree)
        n_features = len(features)
        feature_reuse = n_features / max(n_internal, 1)
        
        return cls(
            depth=depth,
            size=size,
            n_leaves=n_leaves,
            n_internal=n_internal,
            balance=balance,
            n_features_used=n_features,
            feature_reuse_ratio=feature_reuse,
        )


@dataclass
class StructuralPrior:
    """
    Captures LLM's implicit structural preferences for decision trees.
    
    Learned from Phase 1 experiment outputs (LLM-generated trees).
    Used to guide crossover without requiring LLM calls.
    """
    # Depth preferences
    depth_mean: float = 3.0
    depth_std: float = 1.0
    depth_min: int = 1
    depth_max: int = 6
    
    # Size preferences
    size_mean: float = 10.0
    size_std: float = 4.0
    
    # Balance preferences (0 = unbalanced, 1 = balanced)
    balance_mean: float = 0.7
    balance_std: float = 0.3
    
    # Feature reuse preferences
    feature_reuse_mean: float = 0.8
    feature_reuse_std: float = 0.2
    
    # Weights for scoring (learned or set)
    weight_depth: float = 1.0
    weight_size: float = 0.5
    weight_balance: float = 1.0
    weight_feature_reuse: float = 0.5
    
    def score_tree(self, tree: dict) -> float:
        """
        Score how well a tree matches the LLM's structural prior.
        
        Higher score = better match to LLM preferences.
        """
        stats = TreeStats.from_tree(tree)
        
        # Depth score (Gaussian likelihood)
        depth_score = -((stats.depth - self.depth_mean) ** 2) / (2 * self.depth_std ** 2)
        
        # Size score
        size_score = -((stats.size - self.size_mean) ** 2) / (2 * self.size_std ** 2)
        
        # Balance score (prefer balanced trees)
        balance_score = -((stats.balance - self.balance_mean) ** 2) / (2 * self.balance_std ** 2)
        
        # Feature reuse score
        reuse_score = -((stats.feature_reuse_ratio - self.feature_reuse_mean) ** 2) / (2 * self.feature_reuse_std ** 2)
        
        # Weighted sum
        total = (
            self.weight_depth * depth_score +
            self.weight_size * size_score +
            self.weight_balance * balance_score +
            self.weight_feature_reuse * reuse_score
        )
        
        return total
    
    def save(self, path: Path):
        """Save prior to file."""
        with open(path, 'wb') as f:
            pickle.dump(self, f)
    
    @classmethod
    def load(cls, path: Path) -> "StructuralPrior":
        """Load prior from file."""
        with open(path, 'rb') as f:
            return pickle.load(f)
    
    @classmethod
    def fit_from_trees(cls, trees: list[dict]) -> "StructuralPrior":
        """
        Fit structural prior from a corpus of LLM-generated trees.
        
        Args:
            trees: List of tree dictionaries generated by LLM
            
        Returns:
            Fitted StructuralPrior
        """
        if not trees:
            logger.warning("No trees provided, using default prior")
            return cls()
        
        # Compute stats for all trees
        all_stats = [TreeStats.from_tree(t) for t in trees]
        
        depths = [s.depth for s in all_stats]
        sizes = [s.size for s in all_stats]
        balances = [s.balance for s in all_stats]
        reuse_ratios = [s.feature_reuse_ratio for s in all_stats]
        
        prior = cls(
            depth_mean=np.mean(depths),
            depth_std=max(np.std(depths), 0.5),  # Avoid zero std
            depth_min=min(depths),
            depth_max=max(depths),
            size_mean=np.mean(sizes),
            size_std=max(np.std(sizes), 1.0),
            balance_mean=np.mean(balances),
            balance_std=max(np.std(balances), 0.1),
            feature_reuse_mean=np.mean(reuse_ratios),
            feature_reuse_std=max(np.std(reuse_ratios), 0.1),
        )
        
        logger.info(f"Fitted structural prior from {len(trees)} trees:")
        logger.info(f"  Depth: {prior.depth_mean:.2f} ± {prior.depth_std:.2f}")
        logger.info(f"  Size: {prior.size_mean:.2f} ± {prior.size_std:.2f}")
        logger.info(f"  Balance: {prior.balance_mean:.2f} ± {prior.balance_std:.2f}")
        logger.info(f"  Feature reuse: {prior.feature_reuse_mean:.2f} ± {prior.feature_reuse_std:.2f}")
        
        return prior


# =============================================================================
# Tree Utility Functions
# =============================================================================

def compute_depth(tree: dict) -> int:
    """Compute the depth of a tree."""
    if tree is None:
        return 0
    if "class" in tree:
        return 0
    left_depth = compute_depth(tree.get("left", {}))
    right_depth = compute_depth(tree.get("right", {}))
    return 1 + max(left_depth, right_depth)


def compute_size(tree: dict) -> int:
    """Compute the total number of nodes in a tree."""
    if tree is None:
        return 0
    if "class" in tree:
        return 1
    return 1 + compute_size(tree.get("left", {})) + compute_size(tree.get("right", {}))


def count_leaves(tree: dict) -> int:
    """Count the number of leaf nodes."""
    if tree is None:
        return 0
    if "class" in tree:
        return 1
    return count_leaves(tree.get("left", {})) + count_leaves(tree.get("right", {}))


def compute_balance(tree: dict) -> float:
    """
    Compute tree balance ratio.
    
    Returns: 0 (completely unbalanced) to 1 (perfectly balanced)
    """
    if tree is None or "class" in tree:
        return 1.0
    
    left_size = compute_size(tree.get("left", {}))
    right_size = compute_size(tree.get("right", {}))
    total = left_size + right_size
    
    if total == 0:
        return 1.0
    
    # Balance = 1 - |left - right| / total
    return 1.0 - abs(left_size - right_size) / total


def get_features_used(tree: dict) -> set:
    """Get set of features used in tree."""
    if tree is None or "class" in tree:
        return set()
    
    features = {tree.get("feature", "")}
    features.update(get_features_used(tree.get("left", {})))
    features.update(get_features_used(tree.get("right", {})))
    features.discard("")
    return features


def get_all_subtrees(tree: dict) -> list[dict]:
    """Get all subtrees of a tree (for crossover candidates)."""
    subtrees = [tree]
    if "class" not in tree:
        if "left" in tree:
            subtrees.extend(get_all_subtrees(tree["left"]))
        if "right" in tree:
            subtrees.extend(get_all_subtrees(tree["right"]))
    return subtrees


def replace_subtree(tree: dict, old_subtree: dict, new_subtree: dict) -> dict:
    """Replace a subtree in a tree (creates new tree, doesn't modify original)."""
    if tree is old_subtree:
        return copy.deepcopy(new_subtree)
    
    if "class" in tree:
        return copy.deepcopy(tree)
    
    new_tree = {
        "feature": tree["feature"],
        "threshold": tree["threshold"],
        "left": replace_subtree(tree["left"], old_subtree, new_subtree),
        "right": replace_subtree(tree["right"], old_subtree, new_subtree),
    }
    return new_tree


# =============================================================================
# Distilled Evolution
# =============================================================================

class DistilledEvolution:
    """
    Evolutionary algorithm using distilled structural and semantic priors.
    
    This class performs crossover guided by priors WITHOUT any LLM calls:
    1. Structural prior - Learned tree shape preferences (depth, balance, etc.)
    2. Semantic prior - Feature similarity matrix (from SAEs, embeddings, or LLM extraction)
    
    The semantic prior encourages trees that use semantically related features together.
    """
    
    def __init__(
        self,
        structural_prior: StructuralPrior,
        semantic_prior: Optional[pd.DataFrame] = None,
        n_candidates: int = 10,
        fitness_weight: float = 0.5,
        structure_weight: float = 0.3,
        semantic_weight: float = 0.2,
    ):
        """
        Args:
            structural_prior: Learned prior from LLM outputs (tree structure preferences)
            semantic_prior: Optional DataFrame of pairwise feature similarities
                           (index and columns are feature names, values are 0-1 similarity)
            n_candidates: Number of crossover candidates to generate
            fitness_weight: Weight for fitness in candidate selection
            structure_weight: Weight for structural prior in candidate selection
            semantic_weight: Weight for semantic coherence in candidate selection
        """
        self.prior = structural_prior
        self.semantic_prior = semantic_prior
        self.n_candidates = n_candidates
        self.fitness_weight = fitness_weight
        self.structure_weight = structure_weight
        self.semantic_weight = semantic_weight
    
    def crossover(
        self,
        parent1: dict,
        parent2: dict,
        fitness1: float,
        fitness2: float,
        evaluate_fn: Optional[callable] = None,
    ) -> dict:
        """
        Perform crossover guided by structural prior.
        
        Args:
            parent1, parent2: Parent trees (dict format)
            fitness1, fitness2: Fitness values of parents
            evaluate_fn: Optional function to evaluate child fitness
            
        Returns:
            Best child tree according to prior + fitness
        """
        candidates = self._generate_candidates(parent1, parent2)
        
        if not candidates:
            # Fallback: return better parent
            return copy.deepcopy(parent1 if fitness1 >= fitness2 else parent2)
        
        # Score candidates
        scores = []
        for child in candidates:
            struct_score = self.prior.score_tree(child)
            
            # Semantic coherence score (if semantic prior available)
            sem_score = 0.0
            if self.semantic_prior is not None:
                features_used = list(get_features_used(child))
                sem_score = self._compute_semantic_coherence(features_used)
            
            # If we can evaluate fitness, include it
            if evaluate_fn is not None:
                fitness_score = evaluate_fn(child)
                total = (
                    self.fitness_weight * fitness_score +
                    self.structure_weight * struct_score +
                    self.semantic_weight * sem_score
                )
            else:
                # Without fitness evaluation, use structure + semantic heuristic
                total = self.structure_weight * struct_score + self.semantic_weight * sem_score
            
            scores.append(total)
        
        # Return best candidate
        best_idx = np.argmax(scores)
        return candidates[best_idx]
    
    def _compute_semantic_coherence(self, features: list[str]) -> float:
        """
        Compute semantic coherence of features in a tree.
        
        Higher score = features used together are semantically related.
        This encourages trees like:
          - Split on Cholesterol → Split on BloodPressure (related health metrics)
        And discourages:
          - Split on Cholesterol → Split on HairColor (unrelated)
        
        Returns:
            Mean pairwise similarity of features in tree (0-1)
        """
        if self.semantic_prior is None or len(features) < 2:
            return 0.0
        
        total_sim = 0.0
        n_pairs = 0
        
        for f1, f2 in combinations(features, 2):
            # Check if both features are in the similarity matrix
            if f1 in self.semantic_prior.index and f2 in self.semantic_prior.columns:
                total_sim += self.semantic_prior.loc[f1, f2]
                n_pairs += 1
        
        if n_pairs == 0:
            return 0.0
        
        return total_sim / n_pairs
    
    def _generate_candidates(self, parent1: dict, parent2: dict) -> list[dict]:
        """Generate crossover candidates via subtree exchange."""
        candidates = []
        
        subtrees1 = get_all_subtrees(parent1)
        subtrees2 = get_all_subtrees(parent2)
        
        for _ in range(self.n_candidates):
            # Randomly select subtrees to exchange
            if random.random() < 0.5:
                # Take subtree from parent2, insert into parent1
                base = parent1
                donor_subtrees = subtrees2
                base_subtrees = subtrees1
            else:
                # Take subtree from parent1, insert into parent2
                base = parent2
                donor_subtrees = subtrees1
                base_subtrees = subtrees2
            
            if len(base_subtrees) < 2 or len(donor_subtrees) < 1:
                continue
            
            # Select random points
            replace_point = random.choice(base_subtrees[1:])  # Skip root
            donor_subtree = random.choice(donor_subtrees)
            
            # Create child
            child = replace_subtree(base, replace_point, donor_subtree)
            
            # Validate child (not too deep, has valid structure)
            if self._is_valid_tree(child):
                candidates.append(child)
        
        return candidates
    
    def _is_valid_tree(self, tree: dict, max_depth: int = 10) -> bool:
        """Check if tree is valid (not too deep, proper structure)."""
        depth = compute_depth(tree)
        if depth > max_depth:
            return False
        
        size = compute_size(tree)
        if size > 100:  # Sanity check
            return False
        
        return True
    
    def mutation(self, tree: dict, feature_names: list[str], threshold_ranges: dict) -> dict:
        """
        Mutate a tree slightly.
        
        Mutations:
        - Change threshold at a random internal node
        - Change feature at a random internal node
        - Prune a subtree to a leaf
        - Grow a leaf into a split
        """
        tree = copy.deepcopy(tree)
        
        mutation_type = random.choice(["threshold", "feature", "prune", "grow"])
        
        if mutation_type == "threshold" and "threshold" in tree:
            tree = self._mutate_threshold(tree, threshold_ranges)
        elif mutation_type == "feature" and "feature" in tree:
            tree = self._mutate_feature(tree, feature_names)
        elif mutation_type == "prune":
            tree = self._mutate_prune(tree)
        elif mutation_type == "grow" and feature_names:
            tree = self._mutate_grow(tree, feature_names, threshold_ranges)
        
        return tree
    
    def _mutate_threshold(self, tree: dict, threshold_ranges: dict) -> dict:
        """Change a threshold value."""
        if "class" in tree:
            return tree
        
        if random.random() < 0.3:  # Mutate this node
            feature = tree.get("feature", "")
            if feature in threshold_ranges:
                low, high = threshold_ranges[feature]
                tree["threshold"] = random.uniform(low, high)
        else:
            # Recurse
            if random.random() < 0.5 and "left" in tree:
                tree["left"] = self._mutate_threshold(tree["left"], threshold_ranges)
            elif "right" in tree:
                tree["right"] = self._mutate_threshold(tree["right"], threshold_ranges)
        
        return tree
    
    def _mutate_feature(self, tree: dict, feature_names: list[str]) -> dict:
        """Change a feature."""
        if "class" in tree:
            return tree
        
        if random.random() < 0.3:
            tree["feature"] = random.choice(feature_names)
        else:
            if random.random() < 0.5 and "left" in tree:
                tree["left"] = self._mutate_feature(tree["left"], feature_names)
            elif "right" in tree:
                tree["right"] = self._mutate_feature(tree["right"], feature_names)
        
        return tree
    
    def _mutate_prune(self, tree: dict) -> dict:
        """Prune a subtree to a leaf."""
        if "class" in tree:
            return tree
        
        if random.random() < 0.2:
            # Prune this subtree
            return {"class": random.choice([0, 1])}
        
        if random.random() < 0.5:
            tree["left"] = self._mutate_prune(tree["left"])
        else:
            tree["right"] = self._mutate_prune(tree["right"])
        
        return tree
    
    def _mutate_grow(self, tree: dict, feature_names: list[str], threshold_ranges: dict) -> dict:
        """Grow a leaf into a split."""
        if "class" in tree:
            if random.random() < 0.2:
                feature = random.choice(feature_names)
                low, high = threshold_ranges.get(feature, (0, 100))
                return {
                    "feature": feature,
                    "threshold": random.uniform(low, high),
                    "left": {"class": 0},
                    "right": {"class": 1},
                }
            return tree
        
        if random.random() < 0.5:
            tree["left"] = self._mutate_grow(tree["left"], feature_names, threshold_ranges)
        else:
            tree["right"] = self._mutate_grow(tree["right"], feature_names, threshold_ranges)
        
        return tree


# =============================================================================
# Phase 2 Analysis: Extract Priors from Phase 1 Results
# =============================================================================

def load_phase1_trees(results_path: Path) -> list[dict]:
    """Load all successfully parsed trees from Phase 1 results."""
    trees = []
    
    # Load semantic ablation results
    for json_file in results_path.glob("semantic_ablation_*.json"):
        if "_summary" in str(json_file):
            continue
        
        with open(json_file) as f:
            data = json.load(f)
        
        for result in data.get("raw_results", []):
            if result.get("tree_parsed_successfully") and result.get("generated_tree"):
                trees.append(result["generated_tree"])
    
    logger.info(f"Loaded {len(trees)} trees from Phase 1 results")
    return trees


def analyze_phase1_and_fit_prior(results_dir: Path) -> StructuralPrior:
    """
    Analyze Phase 1 results and fit structural prior.
    
    This is the main entry point for Phase 2 distillation.
    """
    trees = load_phase1_trees(results_dir)
    
    if not trees:
        logger.error("No trees found in Phase 1 results!")
        return StructuralPrior()  # Return default
    
    # Fit prior
    prior = StructuralPrior.fit_from_trees(trees)
    
    # Additional analysis: compare semantic vs arbitrary
    logger.info("\n" + "=" * 60)
    logger.info("Phase 1 Key Findings:")
    logger.info("=" * 60)
    logger.info("1. Semantic names do NOT improve LLM performance")
    logger.info("   - Arbitrary (X1, X2) slightly outperformed semantic names")
    logger.info("   - This means: DISTILL STRUCTURE, NOT SEMANTICS")
    logger.info("")
    logger.info("2. LLM DOES use fitness information")
    logger.info("   - Swapping fitness values changed outputs")
    logger.info("   - This means: KEEP FITNESS IN PROMPTS (for comparison)")
    logger.info("")
    logger.info("3. Structural prior parameters (learned from LLM outputs):")
    logger.info(f"   - Preferred depth: {prior.depth_mean:.1f} ± {prior.depth_std:.1f}")
    logger.info(f"   - Preferred size: {prior.size_mean:.1f} ± {prior.size_std:.1f}")
    logger.info(f"   - Preferred balance: {prior.balance_mean:.2f} ± {prior.balance_std:.2f}")
    logger.info("=" * 60)
    
    return prior


# =============================================================================
# Main: Run Phase 2 Analysis
# =============================================================================

if __name__ == "__main__":
    import argparse
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    parser = argparse.ArgumentParser(description="Phase 2: Distillation")
    parser.add_argument(
        "--results-dir",
        type=Path,
        default=Path("mi_analysis/results/phase1"),
        help="Directory containing Phase 1 results",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("mi_analysis/results/phase2"),
        help="Directory to save Phase 2 outputs",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Run with sample data for testing",
    )
    
    args = parser.parse_args()
    
    # Create output directory
    args.output_dir.mkdir(parents=True, exist_ok=True)
    
    if args.dry_run:
        logger.info("Running in dry-run mode with sample data")
        
        # Create sample trees
        sample_trees = [
            {
                "feature": "X1",
                "threshold": 50.0,
                "left": {"class": 0},
                "right": {
                    "feature": "X2",
                    "threshold": 30.0,
                    "left": {"class": 1},
                    "right": {"class": 0}
                }
            },
            {
                "feature": "X2",
                "threshold": 40.0,
                "left": {
                    "feature": "X1",
                    "threshold": 25.0,
                    "left": {"class": 1},
                    "right": {"class": 0}
                },
                "right": {"class": 1}
            },
        ]
        
        prior = StructuralPrior.fit_from_trees(sample_trees)
        
    else:
        # Analyze Phase 1 results
        prior = analyze_phase1_and_fit_prior(args.results_dir)
    
    # Save fitted prior
    prior_path = args.output_dir / "structural_prior.pkl"
    prior.save(prior_path)
    logger.info(f"Saved structural prior to {prior_path}")
    
    # Also save as JSON for inspection
    prior_json = {
        "depth_mean": prior.depth_mean,
        "depth_std": prior.depth_std,
        "depth_min": prior.depth_min,
        "depth_max": prior.depth_max,
        "size_mean": prior.size_mean,
        "size_std": prior.size_std,
        "balance_mean": prior.balance_mean,
        "balance_std": prior.balance_std,
        "feature_reuse_mean": prior.feature_reuse_mean,
        "feature_reuse_std": prior.feature_reuse_std,
    }
    
    json_path = args.output_dir / "structural_prior.json"
    with open(json_path, "w") as f:
        json.dump(prior_json, f, indent=2)
    logger.info(f"Saved prior parameters to {json_path}")
    
    # Test the distilled evolution
    logger.info("\n" + "=" * 60)
    logger.info("Testing DistilledEvolution")
    logger.info("=" * 60)
    
    evo = DistilledEvolution(prior)
    
    # Sample parents
    parent1 = {
        "feature": "X1",
        "threshold": 50.0,
        "left": {"class": 0},
        "right": {
            "feature": "X2",
            "threshold": 30.0,
            "left": {"class": 1},
            "right": {"class": 0}
        }
    }
    
    parent2 = {
        "feature": "X2",
        "threshold": 40.0,
        "left": {
            "feature": "X3",
            "threshold": 25.0,
            "left": {"class": 1},
            "right": {"class": 0}
        },
        "right": {"class": 1}
    }
    
    child = evo.crossover(parent1, parent2, fitness1=0.75, fitness2=0.80)
    
    logger.info(f"Parent 1: depth={compute_depth(parent1)}, size={compute_size(parent1)}")
    logger.info(f"Parent 2: depth={compute_depth(parent2)}, size={compute_size(parent2)}")
    logger.info(f"Child: depth={compute_depth(child)}, size={compute_size(child)}")
    logger.info(f"Child prior score: {prior.score_tree(child):.3f}")
    
    logger.info("\n✅ Phase 2 distillation complete!")
    logger.info(f"Results saved to: {args.output_dir}")
